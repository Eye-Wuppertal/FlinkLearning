# Flink环境搭建

## 1. local本地模式

### 原理

1. Flink程序由JobClient进行提交
2. JobClient将作业提交给JobManager
3. JobManager负责协调资源分配和作业执行。资源分配完成后，任务将提交给相应的TaskManager
4. TaskManager启动一个线程以开始执行。TaskManager会向JobManager报告状态更改,如开始执行，正在进行或已完成。 
5. 作业执行完成后，结果将发送回客户端(JobClient)

![image-20211026133131532](.\img\image-20211026133131532.png)

### 步骤

![image-20211026153014075](.\img\image-20211026153014075.png)

```shell
# 安装解压
tar -zxvf /data/packs/flink-1.14.0-bin-scala_2.12.tgz -C /software/  

 mv /software/flink-1.14.0/ /software/flink/    #修改路径名
```

![image-20211026153538583](.\img\image-20211026153538583.png)

```shell
# 赋予root 权限
chown -R root /software/flink
chgrp -R root /software/flink

# 配置环境变量
vi /etc/profile

# Flink
export FLINK_HOME=/software/flink
export PATH=$PATH:$FLINK_HOME/bin

. /etc/profile

```

### 测试

准备好测试文件

![image-20211026154101651](.\img\image-20211026154101651.png)

```shell
start-cluster.sh # 启动本地“集群”
```

![image-20211026155410464](.\img\image-20211026155410464.png)

访问Flink的Web UI

  http://master:8081/#/overview

![image-20211026155617689](.\img\image-20211026155617689.png)

  slot在Flink里面可以认为是资源组，Flink是通过将任务分成子任务并且将这些子任务分配到slot来并行执行程序。

```shell
# 官方例程
/software/flink/bin/flink run /software//flink/examples/batch/WordCount.jar --input /root/words.txt --output /root/output
```

![image-20211026160051120](.\img\image-20211026160051120.png)

![image-20211026160343092](.\img\image-20211026160343092.png)

```shell
# 停止Flink
stop-cluster.sh
# 或者启动shell交互式窗口(目前所有Scala 2.12版本的安装包暂时都不支持 Scala Shell)
start-scala-shell.sh local #学习版本不支持
```

## Standalone独立集群模式

### 原理

1. client客户端提交任务给JobManager
2. JobManager负责申请任务运行所需要的资源并管理任务和资源，
3. JobManager分发任务给TaskManager执行
4. TaskManager定期向JobManager汇报状态

![image-20211026161512910](F:\FlinkLearning\day02\img\image-20211026161512910.png)

### 步骤

集群规划:

\- 服务器: master(Master + Slave): JobManager + TaskManager

\- 服务器: slave1(Slave): TaskManager

\- 服务器: slave2(Slave): TaskManager

```shell
# 修改flink-conf.yaml
vi /software/flink/conf/flink-conf.yaml

# 添加如下内容
jobmanager.rpc.address: master
taskmanager.numberOfTaskSlots: 2
web.submit.enable: true
# 历史服务器
jobmanager.archive.fs.dir: hdfs://master:9000/flink/completed-jobs/
historyserver.web.address: master
historyserver.web.port: 8082
historyserver.archive.fs.dir: hdfs://master:9000/flink/completed-jobs/

# 修改masters
vi /software/flink/conf/masters
# 添加
master:8081

# 修改slaves
vi /software/flink/conf/workers
# 添加
master
slave1
slave2

# 添加HADOOP_CONF_DIR环境变量
vi /etc/profile
# 添加
export HADOOP_CONF_DIR=/software/hadoop/etc/hadoop

# 将安装的Flink克隆到其他两个节点,profile 文件也一起拷贝
scp -r /software/flink/ slave1:/software/
scp -r /software/flink/ slave2:/software/
scp /etc/profile slave1:/etc/
scp /etc/profile slave2:/etc/
. /etc/profile	
```

### 测试

```shell
# master上启动集群
start-cluster.sh
# 或者单独启动
jobmanager.sh ((start|start-foreground) cluster)|stop|stop-all
taskmanager.sh start|start-foreground|stop|stop-all

# 启动历史服务器
historyserver.sh start
```

![image-20211026164035462](.\img\image-20211026164035462.png)

访问Flink UI界面或使用jps查看

![image-20211026181812663](.\img\image-20211026181812663.png)

http://master:8081/#/overview

http://msater:8082/#/overview

![image-20211026181717224](.\img\image-20211026181717224.png)

```shell
# 测试官方案例
/software/flink/bin/flink run /software/flink/examples/batch/WordCount.jar
```

配置历史服务器时出现的问题，查看历史服务器启动日志

```shell
historyserver.sh start-foreground

# 发现问题是flink cannot create hadoop security module because hadoop cannot be found in the classpath

# 因此在profile中添加
export HADOOP_CLASSPATH=`hadoop classpath`

# 问题解决
```

参考：https://www.cnblogs.com/quchunhui/p/12463455.html

![image-20211026181400241](.\img\image-20211026181400241.png)

